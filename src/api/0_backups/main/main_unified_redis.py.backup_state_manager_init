"""
Punto de entrada principal unificado para la API del sistema de recomendaciones
con integraci√≥n de Redis para cach√©.

Este archivo implementa la API REST para el sistema de recomendaciones,
utilizando la configuraci√≥n centralizada, las f√°bricas de componentes
y el sistema de cach√© con Redis.
"""

import os
import time
import logging
import asyncio
from dotenv import load_dotenv
from datetime import datetime

# ‚úÖ CONFIGURAR LOGGING INMEDIATAMENTE para capturar mensajes de importaci√≥n
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Ahora s√≠, imports que pueden generar logs
from fastapi import FastAPI, Header, Query, HTTPException, BackgroundTasks, Response, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any
import math
import random
import json
from src.api.core.redis_config_fix import RedisConfigValidator, PatchedRedisClient

# ‚úÖ IMPORT OBSERVABILITY MANAGER CON LOGGING YA CONFIGURADO
try:
    from src.api.core.observability_manager import get_observability_manager
    OBSERVABILITY_MANAGER_AVAILABLE = True
    logger.info("‚úÖ ObservabilityManager loaded - Single source of truth enabled")
    
    # Test adicional para confirmar funcionalidad completa
    try:
        _test_observability = get_observability_manager()
        if hasattr(_test_observability, 'metrics_collector'):
            logger.info("‚úÖ MetricsCollector integrated successfully - Middleware ready")
        else:
            logger.warning("‚ö†Ô∏è MetricsCollector not found in ObservabilityManager")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è ObservabilityManager test failed: {e}")
        
except ImportError as e:
    OBSERVABILITY_MANAGER_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è ObservabilityManager not available: {e}")


# Intentar cargar variables de entorno, pero continuar si no existe el archivo
try:
    load_dotenv()
    logger.info("Variables de entorno cargadas desde .env")
except Exception as e:
    logger.warning(f"No se pudo cargar .env, usando variables de entorno del sistema: {e}")

# Importar configuraci√≥n centralizada
from src.api.core.config import get_settings
from src.api.factories import RecommenderFactory
from src.api.startup_helper import StartupManager
from src.api.core.store import get_shopify_client, init_shopify
from src.api.security_auth import get_api_key, get_current_user

# Importar routers
from src.api.routers import mcp_router
from src.api.routers import products_router  # ‚úÖ A√ëADIDO

# Importar OptimizedConversationAIManager para Fase 0
from src.api.integrations.ai.optimized_conversation_manager import OptimizedConversationAIManager

# Configurar logger b√°sico para imports
import logging
logger = logging.getLogger(__name__)

# === FASE 2: MCP PERSONALIZATION ENGINE ===
try:
    from src.api.mcp.engines.mcp_personalization_engine import (
        MCPPersonalizationEngine,
        create_mcp_personalization_engine,
        PersonalizationStrategy,
        PersonalizationInsightsAnalyzer  # ‚Üê COMENTADO TEMPORALMENTE
    )
    # from src.api.routers.mcp_conversation_state_fix import ConversationStateManager
    from src.api.mcp.conversation_state_manager import MCPConversationStateManager as ConversationStateManager
    MCP_PERSONALIZATION_AVAILABLE = True
    logger.info("‚úÖ MCP Personalization Engine imports successful")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è MCP Personalization Engine not available: {e}")
    MCP_PERSONALIZATION_AVAILABLE = False

# === FASE 3: IMPORTS PARA COMPONENTES AVANZADOS ===
# Health checks extendidos
try:
    from src.api.health.claude_health import get_claude_health, claude_health_checker
    CLAUDE_HEALTH_AVAILABLE = True
    logger.info("‚úÖ Claude Health module loaded")
except ImportError as e:
    CLAUDE_HEALTH_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Claude Health module not available: {e}")

# Advanced monitoring
try:
    from src.api.monitoring.claude_monitoring import (
        get_claude_metrics, 
        get_claude_historical_metrics, 
        get_claude_alerts,
        record_claude_request,
        claude_metrics_collector
    )
    CLAUDE_MONITORING_AVAILABLE = True
    logger.info("‚úÖ Claude Monitoring module loaded")
except ImportError as e:
    CLAUDE_MONITORING_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Claude Monitoring module not available: {e}")

# Security audit
try:
    from src.api.security.claude_security_audit import run_claude_security_audit
    CLAUDE_SECURITY_AVAILABLE = True
    logger.info("‚úÖ Claude Security module loaded")
except ImportError as e:
    CLAUDE_SECURITY_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Claude Security module not available: {e}")

# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Cargar configuraci√≥n
settings = get_settings()

# Crear aplicaci√≥n FastAPI
app = FastAPI(
    title="Retail Recommender API",
    description="API para sistema de recomendaciones de retail con cach√© Redis",
    version=settings.app_version
)

# Agregar middleware CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Crear recomendadores usando las f√°bricas
tfidf_recommender = RecommenderFactory.create_tfidf_recommender()
retail_recommender = RecommenderFactory.create_retail_recommender()

# Variables globales para Redis y cach√© de productos
redis_client = None
product_cache = None

# Inicialmente crear el recomendador h√≠brido sin cach√©
# Se actualizar√° despu√©s con la cach√© en el evento de startup
hybrid_recommender = RecommenderFactory.create_hybrid_recommender(
    tfidf_recommender, retail_recommender
)

# Inicialmente el recomendador MCP es None, se inicializar√° en startup
mcp_recommender = None

# Variables globales para conversaci√≥n AI optimizada (Fase 0)
optimized_conversation_manager = None

# Variables globales para MCP state management
mcp_state_manager = None

# Crear gestor de arranque
startup_manager = StartupManager(startup_timeout=settings.startup_timeout)

# Incluir router MCP
app.include_router(mcp_router.router)

# Incluir router de productos
app.include_router(products_router.router)

# Variables para uptime
start_time = time.time()

# Cargar extensiones seg√∫n configuraci√≥n
if settings.metrics_enabled:
    from src.api.extensions.metrics_extension import MetricsExtension
    metrics_extension = MetricsExtension(app, settings)
    metrics_extension.setup()

# Modelos de datos
class HealthStatus(BaseModel):
    status: str = Field(description="Estado general del servicio")
    components: Dict[str, Any] = Field(description="Estado de los componentes")
    uptime_seconds: float = Field(description="Tiempo de funcionamiento en segundos")

# Funci√≥n para la carga as√≠ncrona de productos y modelos
async def load_shopify_products():
    """Carga productos desde Shopify."""
    try:
        # Inicializar cliente Shopify
        client = init_shopify()
        if client:
            products = client.get_products()
            logger.info(f"Cargados {len(products)} productos desde Shopify")
            if products:
                logger.info(f"Primer producto: {products[0].get('title', 'No title')}")
            return products
        else:
            logger.warning("No se pudo inicializar el cliente de Shopify, intentando cargar productos de muestra")
    except Exception as e:
        logger.error(f"Error cargando productos desde Shopify: {e}")
    
    # Si falla Shopify, intentar cargar productos de muestra
    return await load_sample_data()

async def load_sample_data():
    """Carga datos de muestra para el recomendador si no se pueden obtener de Shopify."""
    try:
        # Intento 1: Cargar desde datos de muestra en el m√≥dulo
        from src.api.core.sample_data import SAMPLE_PRODUCTS
        if SAMPLE_PRODUCTS:
            logger.info(f"Cargados {len(SAMPLE_PRODUCTS)} productos de muestra")
            return SAMPLE_PRODUCTS
    except Exception as e:
        logger.warning(f"No se pudieron cargar productos de muestra desde c√≥digo: {e}")
    
    # Datos m√≠nimos de fallback
    minimal_products = [
        {
            "id": "product1",
            "title": "Camiseta b√°sica",
            "body_html": "Camiseta de algod√≥n de alta calidad.",
            "product_type": "Ropa"
        },
        {
            "id": "product2",
            "title": "Pantal√≥n vaquero",
            "body_html": "Pantal√≥n vaquero cl√°sico de corte recto.",
            "product_type": "Ropa"
        },
        {
            "id": "product3",
            "title": "Zapatillas deportivas",
            "body_html": "Zapatillas para running con amortiguaci√≥n.",
            "product_type": "Calzado"
        }
    ]
    logger.info(f"Usando {len(minimal_products)} productos m√≠nimos de muestra")
    return minimal_products

async def load_recommender():
    """Carga y entrena el recomendador TF-IDF con productos de Shopify."""
    try:
        # Intentar cargar modelo pre-entrenado
        if os.path.exists("data/tfidf_model.pkl"):
            success = await tfidf_recommender.load()
            if success:
                logger.info("Modelo TF-IDF cargado correctamente desde archivo")
                return True
        
        # Si no existe o falla, entrenar con datos de Shopify o muestra
        products = await load_shopify_products()
        if not products:
            logger.error("No se pudieron cargar productos de ninguna fuente")
            return False
            
        logger.info(f"Entrenando recomendador TF-IDF con {len(products)} productos")
        success = await tfidf_recommender.fit(products)
        
        if success:
            logger.info("Recomendador TF-IDF entrenado correctamente")
            
            # Importar productos a Google Cloud Retail API
            try:
                logger.info("Importando productos a Google Cloud Retail API")
                import_result = await retail_recommender.import_catalog(products)
                logger.info(f"Resultado de importaci√≥n: {import_result}")
            except Exception as e:
                logger.error(f"Error importando productos a Google Cloud Retail API: {str(e)}")
        else:
            logger.error("Error entrenando recomendador TF-IDF")
            
        return success
    except Exception as e:
        logger.error(f"Error cargando recomendador: {e}")
        return False
    
logger = logging.getLogger(__name__)

@app.on_event("startup")
async def fixed_startup_event():
    # ‚úÖ CORRECCI√ìN: Declaraciones globales movidas al inicio
    global redis_client, product_cache, hybrid_recommender, mcp_recommender
    global mcp_recommender
    global optimized_conversation_manager, mcp_state_manager, personalization_engine

    """
    Versi√≥n corregida del startup_event con manejo robusto de Redis.
    
    Reemplazar el startup_event existente con esta implementaci√≥n.
    """
    redis_client = None
    product_cache = None
    mcp_recommender = None
    optimized_conversation_manager = None
    mcp_state_manager = None
    personalization_engine = None

    logger.info("üöÄ Iniciando API de recomendaciones unificada con Redis CORREGIDO...")
    
    # üîß CORRECCI√ìN CR√çTICA: Declarar variables globales al inicio
    
    # Verificar estructura del cat√°logo en Retail API si est√° habilitado
    from src.api.core.config import get_settings
    settings = get_settings()
    
    if settings.validate_products:
        try:
            logger.info("Verificando estructura del cat√°logo en Google Cloud Retail API...")
            # Asumir que retail_recommender est√° disponible globalmente
            await retail_recommender.ensure_catalog_branches()
        except Exception as e:
            logger.warning(f"Error al verificar estructura del cat√°logo: {str(e)}")
    
    # ==========================================
    # INICIALIZACI√ìN REDIS CORREGIDA
    # ==========================================
    
    # üîß CORRECCI√ìN: Solo variable local para control de flujo
    redis_initialization_successful = False
    
    logger.info("üîß Iniciando inicializaci√≥n Redis corregida...")
    
    try:
        # PASO 1: Validar configuraci√≥n Redis
        from src.api.core.redis_config_fix import RedisConfigValidator, PatchedRedisClient
        
        config = RedisConfigValidator.validate_and_fix_config()
        
        if not config.get('use_redis_cache'):
            logger.info("‚ö†Ô∏è Redis cache desactivado por configuraci√≥n - continuando sin cache")
            redis_initialization_successful = False
        else:
            logger.info("‚úÖ Configuraci√≥n Redis validada correctamente")
            
            # PASO 2: Crear cliente Redis con configuraci√≥n validada
            try:
                redis_client = PatchedRedisClient(use_validated_config=True)
                logger.info(f"‚úÖ Cliente Redis creado con SSL={redis_client.ssl}")
                
                # PASO 3: Conectar con retry autom√°tico
                connection_successful = await redis_client.connect()
                
                if connection_successful:
                    logger.info("‚úÖ Cliente Redis conectado exitosamente")
                    redis_initialization_successful = True
                    
                    # PASO 4: Verificar operaciones b√°sicas
                    test_result = await redis_client.set("startup_test", "success", ex=30)
                    if test_result:
                        logger.info("‚úÖ Operaciones Redis verificadas correctamente")
                    else:
                        logger.warning("‚ö†Ô∏è Redis conectado pero operaciones fallan")
                        
                else:
                    logger.error("‚ùå No se pudo conectar a Redis despu√©s de intentos")
                    redis_client = None
                    redis_initialization_successful = False
                    
            except Exception as redis_error:
                logger.error(f"‚ùå Error inicializando cliente Redis: {redis_error}")
                redis_client = None
                redis_initialization_successful = False
                
    except Exception as config_error:
        logger.error(f"‚ùå Error en configuraci√≥n Redis: {config_error}")
        redis_initialization_successful = False
    
    # ==========================================
    # CREACI√ìN DE PRODUCT CACHE CONDICIONAL
    # ==========================================
    
    if redis_initialization_successful and redis_client:
        try:
            logger.info("üöÄ Creando ProductCache con Redis habilitado...")
            
            from src.api.core.product_cache import ProductCache
            from src.api.core.store import get_shopify_client
            
            product_cache = ProductCache(
                redis_client=redis_client,
                local_catalog=tfidf_recommender,  # Asumiendo disponibilidad global
                shopify_client=get_shopify_client(),
                ttl_seconds=settings.cache_ttl,
                prefix=settings.cache_prefix
            )
            
            logger.info("‚úÖ ProductCache creado exitosamente")
            
            # Verificar salud del cach√© inmediatamente
            cache_stats = product_cache.get_stats()
            logger.info(f"üìä Estado inicial del cach√©: hit_ratio={cache_stats['hit_ratio']}")
            
            # Iniciar tareas en segundo plano si est√° configurado
            if settings.cache_enable_background_tasks:
                asyncio.create_task(product_cache.start_background_tasks())
                logger.info("üîÑ Tareas en segundo plano de ProductCache iniciadas")
                
        except Exception as cache_error:
            logger.error(f"‚ùå Error creando ProductCache: {cache_error}")
            product_cache = None
            
    else:
        logger.warning("‚ö†Ô∏è ProductCache desactivado porque Redis no est√° disponible")
        product_cache = None
    
    # ==========================================
    # ACTUALIZACI√ìN DEL HYBRID RECOMMENDER
    # ==========================================
    
    try:
        from src.api.factories import RecommenderFactory
        
        # Actualizar hybrid_recommender global para usar la cach√© si est√° disponible
        hybrid_recommender = RecommenderFactory.create_hybrid_recommender(
            tfidf_recommender,
            retail_recommender,
            product_cache=product_cache
        )
        
        if product_cache:
            logger.info("‚úÖ Recomendador h√≠brido actualizado con cach√© Redis")
        else:
            logger.info("‚úÖ Recomendador h√≠brido funcionando sin cach√©")
            
    except Exception as hybrid_error:
        logger.error(f"‚ùå Error actualizando recomendador h√≠brido: {hybrid_error}")
    
    # ==========================================
    # INICIALIZACI√ìN MCP (OPCIONAL)
    # ==========================================
    
    mcp_recommender = None
    
    try:
        if settings.debug:  # Solo en modo debug por ahora
            from src.api.factories import MCPFactory
            
            logger.info("ü§ñ Inicializando componentes MCP...")
            
            # Crear componentes MCP
            mcp_client = MCPFactory.create_mcp_client()
            market_manager = MCPFactory.create_market_manager()
            market_cache = MCPFactory.create_market_cache()
            
            # Crear user event store con Redis (si est√° disponible)
            user_event_store = None
            if redis_client:
                user_event_store = RecommenderFactory.create_user_event_store(redis_client)
            
            # Crear recomendador MCP
            mcp_recommender = MCPFactory.create_mcp_recommender_fixed(
                base_recommender=hybrid_recommender,
                mcp_client=mcp_client,
                market_manager=market_manager,
                market_cache=market_cache,
                user_event_store=user_event_store,
                redis_client=redis_client
            )
            
            if mcp_recommender:
                logger.info("‚úÖ Recomendador MCP inicializado correctamente")
            else:
                logger.warning("‚ö†Ô∏è Recomendador MCP no disponible")
                
    except Exception as mcp_error:
        logger.error(f"‚ùå Error inicializando componentes MCP: {mcp_error}")
        logger.info("Continuando sin soporte MCP...")
    
    # ==========================================
    # REGISTRAR COMPONENTES EN STARTUP MANAGER
    # ==========================================
    
    # Asumir que startup_manager est√° disponible globalmente
    startup_manager.register_component(
        name="recommender",
        loader=load_recommender,  # Asumiendo funci√≥n disponible
        required=True
    )
    
    # Esperar a que termine la carga del recomendador
    logger.info("‚è≥ Esperando a que termine la carga del recomendador...")
    loading_task = asyncio.create_task(startup_manager.start_loading())
    
    try:
        await asyncio.wait_for(loading_task, timeout=30.0)
        logger.info("‚úÖ Carga del recomendador completada")
    except asyncio.TimeoutError:
        logger.warning("‚ö†Ô∏è Timeout esperando carga del recomendador - continuando anyway")
    except Exception as e:
        logger.error(f"‚ùå Error en carga del recomendador: {e}")
    
    # ==========================================
    # DATOS DE PRUEBA (SI DEBUG EST√Å ACTIVADO)
    # ==========================================
    
    if settings.debug:
        try:
            from src.api.core.event_generator import initialize_with_test_data
            logger.info("üß™ Modo DEBUG: Programando generaci√≥n de datos de prueba")
            asyncio.create_task(
                initialize_with_test_data(retail_recommender, tfidf_recommender)
            )
        except ImportError:
            logger.warning("‚ö†Ô∏è event_generator no disponible para datos de prueba")
        except Exception as e:
            logger.error(f"‚ùå Error configurando datos de prueba: {e}")
    
    # ==========================================
    # RESUMEN FINAL DEL STARTUP
    # ==========================================
    
    logger.info("üìã RESUMEN DE INICIALIZACI√ìN:")
    logger.info(f"   ‚úÖ Recomendador TF-IDF: Disponible")
    logger.info(f"   ‚úÖ Recomendador Retail API: Disponible")
    logger.info(f"   ‚úÖ Recomendador H√≠brido: Disponible")
    logger.info(f"   {'‚úÖ' if redis_initialization_successful else '‚ùå'} Redis: {'Conectado' if redis_initialization_successful else 'No disponible'}")
    logger.info(f"   {'‚úÖ' if product_cache else '‚ùå'} ProductCache: {'Activo' if product_cache else 'Desactivado'}")
    logger.info(f"   {'‚úÖ' if mcp_recommender else '‚ùå'} MCP: {'Disponible' if mcp_recommender else 'No disponible'}")
    logger.info(f"   {'‚úÖ' if personalization_engine else '‚ùå'} Personalization: {'Disponible' if personalization_engine else 'No disponible'}")
    logger.info(f"   {'‚úÖ' if optimized_conversation_manager else '‚ùå'} Conversation AI: {'Disponible' if optimized_conversation_manager else 'No disponible'}")
    logger.info(f"   {'‚úÖ' if mcp_state_manager else '‚ùå'} State Manager: {'Disponible' if mcp_state_manager else 'No disponible'}")
    
    if not redis_initialization_successful:
        logger.warning("‚ö†Ô∏è IMPORTANTE: Sistema funcionando sin Redis")
        logger.warning("   - Las recomendaciones funcionar√°n pero sin cach√©")
        logger.warning("   - Rendimiento puede ser menor")
        logger.warning("   - Ejecutar diagn√≥stico: python diagnose_redis_issue.py")
    
    # ==========================================
    # FASE 2: INICIALIZACI√ìN MCP PERSONALIZATION ENGINE
    # ==========================================
    
    optimized_conversation_manager = None
    mcp_state_manager = None 
    personalization_engine = None
    
    if MCP_PERSONALIZATION_AVAILABLE and os.getenv("MCP_PERSONALIZATION_ENABLED", "false").lower() == "true":
        try:
            logger.info("üéØ FASE 2: Inicializando MCP Personalization Engine...")
            
            # Paso 1: Inicializar OptimizedConversationAIManager
            if os.getenv("ANTHROPIC_API_KEY"):
                optimized_conversation_manager = OptimizedConversationAIManager(
                    anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
                    redis_client=redis_client,
                    perplexity_api_key=os.getenv("PERPLEXITY_API_KEY"),
                    use_perplexity_validation=os.getenv("USE_PERPLEXITY_VALIDATION", "false").lower() == "true",
                    enable_caching=True,
                    enable_circuit_breaker=True
                )
                logger.info("‚úÖ OptimizedConversationAIManager inicializado")
            else:
                logger.error("‚ùå ANTHROPIC_API_KEY no configurado")
                raise ValueError("Missing ANTHROPIC_API_KEY")
            
            # Paso 2: Inicializar MCPConversationStateManager
            if redis_client:
                mcp_state_manager = ConversationStateManager(
                    redis_client=redis_client,
                    state_ttl=int(os.getenv("PERSONALIZATION_CACHE_TTL", "3600")),
                    conversation_ttl=int(os.getenv("PERSONALIZATION_PROFILE_TTL", "604800")),
                    max_turns_per_session=int(os.getenv("MAX_CONVERSATION_HISTORY", "50"))
                )
                logger.info("‚úÖ MCPConversationStateManager inicializado")
            else:
                logger.warning("‚ö†Ô∏è Redis no disponible - MCPConversationStateManager con funcionalidad limitada")
                # Crear con configuraci√≥n m√≠nima para desarrollo
                mcp_state_manager = ConversationStateManager(
                    redis_client=None,
                    state_ttl=3600,
                    conversation_ttl=604800
                )
            
            # Paso 3: Crear MCPPersonalizationEngine
            personalization_engine = create_mcp_personalization_engine(
                redis_client=redis_client,
                anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
                conversation_manager=optimized_conversation_manager,
                state_manager=mcp_state_manager,
                profile_ttl=int(os.getenv("PERSONALIZATION_PROFILE_TTL", "604800")),
                enable_ml_predictions=os.getenv("ENABLE_ML_PREDICTIONS", "true").lower() == "true"
            )
            
            logger.info("üéâ MCPPersonalizationEngine creado exitosamente")
            
            # Paso 4: Verificar funcionalidad b√°sica
            try:
                metrics = personalization_engine.get_personalization_metrics()
                logger.info(f"üìä M√©tricas de personalizaci√≥n: {metrics['strategies_available']} estrategias disponibles")
                logger.info(f"üìä Mercados configurados: {metrics['markets_configured']}")
                logger.info(f"üìä ML predictions: {'habilitado' if metrics['ml_predictions_enabled'] else 'deshabilitado'}")
            except Exception as metrics_error:
                logger.warning(f"‚ö†Ô∏è Error obteniendo m√©tricas de personalizaci√≥n: {metrics_error}")
            
            logger.info("‚úÖ FASE 2 completada: Sistema de personalizaci√≥n operativo")
            
        except Exception as personalization_error:
            logger.error(f"‚ùå Error inicializando MCP Personalization Engine: {personalization_error}")
            logger.warning("‚ö†Ô∏è Sistema funcionar√° sin personalizaci√≥n avanzada")
            personalization_engine = None
            optimized_conversation_manager = None
            mcp_state_manager = None
    else:
        if not MCP_PERSONALIZATION_AVAILABLE:
            logger.warning("‚ö†Ô∏è MCP Personalization Engine no disponible (imports fallaron)")
        else:
            logger.info("‚ÑπÔ∏è MCP Personalization Engine deshabilitado por configuraci√≥n")
    
    logger.info("üéâ Inicializaci√≥n completada!")


# Funci√≥n auxiliar para health check mejorado
def get_enhanced_cache_status(product_cache, redis_client) -> dict:
    """
    Obtiene estado detallado del cach√© para el endpoint /health.
    
    Args:
        product_cache: Instancia de ProductCache
        redis_client: Cliente Redis
        
    Returns:
        dict: Estado detallado del cach√©
    """
    if not product_cache:
        return {
            "status": "unavailable",
            "message": "Product cache not initialized",
            "redis_connection": "not_configured"
        }
    
    try:
        cache_stats = product_cache.get_stats()
        
        # Determinar estado de Redis
        redis_status = "unknown"
        if product_cache.redis:
            redis_status = "connected" if product_cache.redis.connected else "disconnected"
        
        # Determinar estado general
        if redis_status == "connected":
            status = "operational"
        elif redis_status == "disconnected":
            status = "degraded"
        else:
            status = "error"
        
        return {
            "status": status,
            "redis_connection": redis_status,
            "hit_ratio": cache_stats["hit_ratio"],
            "stats": cache_stats,
            "fallback_sources": {
                "local_catalog": "available" if product_cache.local_catalog else "unavailable",
                "shopify_client": "available" if product_cache.shopify_client else "unavailable"
            }
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "redis_connection": "error"
        }

@app.get("/", include_in_schema=False)
def read_root():
    return {
        "message": "Retail Recommender API unificada con Redis y MCP",
        "version": settings.app_version,
        "status": "online",
        "docs_url": "/docs",
        "mcp_support": mcp_recommender is not None
    }

@app.get("/debug/globals")
async def debug_globals():
    """Endpoint de debugging para verificar variables globales."""
    global redis_client, product_cache, hybrid_recommender, mcp_recommender
    
    return {
        "redis_client": {
            "type": type(redis_client).__name__ if redis_client else "None",
            "connected": redis_client.connected if redis_client else False,
            "ssl": redis_client.ssl if redis_client else "N/A"
        },
        "product_cache": {
            "type": type(product_cache).__name__ if product_cache else "None",
            "redis_available": bool(product_cache and product_cache.redis) if product_cache else False
        },
        "hybrid_recommender": {
            "type": type(hybrid_recommender).__name__ if hybrid_recommender else "None",
            "has_cache": bool(hasattr(hybrid_recommender, 'product_cache') and hybrid_recommender.product_cache) if hybrid_recommender else False
        },
        "mcp_recommender": {
            "type": type(mcp_recommender).__name__ if mcp_recommender else "None"
        }
    }

@app.get("/health", response_model=HealthStatus)
async def unified_health_check():
    """Health check general unificado que incluye estado de observability"""
    
    # Usar observability manager para Claude status
    try:
        if OBSERVABILITY_MANAGER_AVAILABLE:
            observability = get_observability_manager()
            claude_state = await observability.get_unified_state()
            claude_status = {
                "status": claude_state.overall_status.value,
                "model_tier": observability.claude_config.claude_model_tier.value,
                "error_rate": claude_state.error_rate,
                "sla_compliance": claude_state.sla_compliance,
                "active_alerts": len(claude_state.active_alerts),
                "unified_monitoring": True
            }
        elif CLAUDE_HEALTH_AVAILABLE:
            # Fallback a health checker individual
            claude_health = await get_claude_health()
            claude_status = {
                "status": claude_health.get("overall_status", "unknown"),
                "unified_monitoring": False
            }
        else:
            claude_status = {
                "status": "unavailable",
                "unified_monitoring": False
            }
    except Exception as e:
        claude_status = {
            "status": "error",
            "error": str(e),
            "unified_monitoring": False
        }
    
    # Health check de otros componentes (mantener l√≥gica existente)
    recommender_status = await tfidf_recommender.health_check()
    startup_status = startup_manager.get_status()
    
    # Cache status (mantener l√≥gica existente)
    global product_cache, redis_client
    cache_status = get_enhanced_cache_status(product_cache, redis_client)
    
    return {
        "status": startup_status["status"],
        "components": {
            "recommender": recommender_status,
            "startup": startup_status,
            "cache": cache_status,
            "claude": claude_status  # Unificado
        },
        "uptime_seconds": time.time() - start_time,
        "observability": {
            "unified_monitoring": OBSERVABILITY_MANAGER_AVAILABLE,
            "single_source_of_truth": OBSERVABILITY_MANAGER_AVAILABLE,
            "claude_health_available": CLAUDE_HEALTH_AVAILABLE,
            "claude_monitoring_available": CLAUDE_MONITORING_AVAILABLE,
            "claude_security_available": CLAUDE_SECURITY_AVAILABLE
        },
        "debug_info": {
            "globals_status": "available",
            "check_debug_endpoint": "/debug/globals"
        }
    }

@app.get("/v1/recommendations/{product_id}", response_model=Dict)
async def get_recommendations(
    product_id: str,
    user_id: Optional[str] = Header(None),
    n: Optional[int] = Query(5, gt=0, le=20),
    content_weight: Optional[float] = Query(0.5, ge=0.0, le=1.0),
    current_user: str = Depends(get_current_user)
):
    """
    Obtiene recomendaciones basadas en un producto.
    Requiere autenticaci√≥n mediante API key.
    """
    start_processing = time.time()
    
    # Verificar estado de carga
    is_healthy, reason = startup_manager.is_healthy()
    if not is_healthy:
        raise HTTPException(status_code=503, detail=f"Servicio no disponible: {reason}")
    
    # Obtener recomendaciones
    try:
        # Actualizar peso de contenido en el recomendador h√≠brido
        hybrid_recommender.content_weight = content_weight
        
        # Obtener producto espec√≠fico
        client = get_shopify_client()
        product = None
        
        if client:
            # Obtener productos
            all_products = client.get_products()
            
            # Encontrar el producto espec√≠fico
            product = next(
                (p for p in all_products if str(p.get('id')) == str(product_id)),
                None
            )
        
        if not product and tfidf_recommender.loaded:
            # Intentar obtener producto del recomendador
            product = tfidf_recommender.get_product_by_id(product_id)
        
        if not product:
            # Cambiar a HTTPException para mantener consistencia
            raise HTTPException(
                status_code=404,
                detail=f"Product ID {product_id} not found"
            )
            
        # Obtener recomendaciones del recomendador h√≠brido
        recommendations = await hybrid_recommender.get_recommendations(
            user_id=user_id or "anonymous",
            product_id=str(product_id),
            n_recommendations=n
        )
        
        # Calcular tiempo de procesamiento
        processing_time_ms = (time.time() - start_processing) * 1000
        
        # Registrar m√©tricas si est√°n habilitadas
        if settings.metrics_enabled and 'recommendation_metrics' in globals():
            from src.api.core.metrics import recommendation_metrics
            recommendation_metrics.record_recommendation_request(
                request_data={
                    "product_id": product_id,
                    "user_id": user_id or "anonymous",
                    "n": n,
                    "content_weight": content_weight
                },
                recommendations=recommendations,
                response_time_ms=processing_time_ms,
                user_id=user_id or "anonymous",
                product_id=product_id
            )
        
        return {
            "product": {
                "id": product.get('id'),
                "title": product.get('title')
            },
            "recommendations": recommendations,
            "metadata": {
                "content_weight": content_weight,
                "total_recommendations": len(recommendations),
                "source": "hybrid_tfidf_redis",
                "took_ms": processing_time_ms
            }
        }
    except HTTPException:
        # Re-lanzar HTTPExceptions directamente para mantener el c√≥digo y mensaje
        raise
    except ValueError as e:
        # Convertir ValueError a HTTPException 404
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        logger.error(f"Error obteniendo recomendaciones: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/v1/recommendations/user/{user_id}", response_model=Dict)
async def get_user_recommendations(
    user_id: str,
    n: Optional[int] = Query(5, gt=0, le=20),
    current_user: str = Depends(get_current_user)
):
    """
    Obtiene recomendaciones personalizadas para un usuario.
    Requiere autenticaci√≥n mediante API key.
    """
    start_processing = time.time()
    
    # Verificar estado de carga
    is_healthy, reason = startup_manager.is_healthy()
    if not is_healthy:
        raise HTTPException(status_code=503, detail=f"Servicio no disponible: {reason}")
    
    try:
        client = get_shopify_client()
        
        logger.info(f"Obteniendo recomendaciones para usuario {user_id}")
        
        # Obtener √≥rdenes del usuario si est√° disponible Shopify
        user_orders = []
        if client:
            user_orders = client.get_orders_by_customer(user_id)
            
            if user_orders:
                logger.info(f"Se encontraron {len(user_orders)} √≥rdenes para el usuario {user_id}")
                
                # Registrar eventos de usuario basados en √≥rdenes
                try:
                    await retail_recommender.process_shopify_orders(user_orders, user_id)
                    logger.info(f"Eventos de √≥rdenes procesados para usuario {user_id}")
                except Exception as e:
                    logger.error(f"Error procesando √≥rdenes: {e}")
            else:
                logger.info(f"No se encontraron √≥rdenes para el usuario {user_id}")
        
        # Obtener recomendaciones
        recommendations = await hybrid_recommender.get_recommendations(
            user_id=user_id,
            n_recommendations=n
        )
        
        # Calcular tiempo de procesamiento
        processing_time_ms = (time.time() - start_processing) * 1000
        
        # Registrar m√©tricas si est√°n habilitadas
        if settings.metrics_enabled and 'recommendation_metrics' in globals():
            from src.api.core.metrics import recommendation_metrics
            recommendation_metrics.record_recommendation_request(
                request_data={
                    "user_id": user_id,
                    "n": n
                },
                recommendations=recommendations,
                response_time_ms=processing_time_ms,
                user_id=user_id,
                product_id=None
            )
        
        return {
            "recommendations": recommendations,
            "metadata": {
                "user_id": user_id,
                "total_recommendations": len(recommendations),
                "total_orders": len(user_orders) if user_orders else 0,
                "source": "hybrid_tfidf_user_redis",
                "took_ms": processing_time_ms
            }
        }
    except Exception as e:
        logger.error(f"Error obteniendo recomendaciones para usuario {user_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error obteniendo recomendaciones: {str(e)}"
        )

@app.post("/v1/events/user/{user_id}")
async def record_user_event(
    user_id: str,
    event_type: str = Query(..., description="Tipo de evento (detail-page-view, add-to-cart, purchase-complete, etc.)"),
    product_id: Optional[str] = Query(None, description="ID del producto relacionado con el evento"),
    purchase_amount: Optional[float] = Query(None, description="Monto de la compra para eventos de tipo purchase-complete"),
    current_user: str = Depends(get_current_user)
):
    """
    Registra eventos de usuario para mejorar las recomendaciones futuras.
    Requiere autenticaci√≥n mediante API key.
    
    Tipos de eventos v√°lidos seg√∫n Google Cloud Retail API:
    - add-to-cart: Cuando un usuario a√±ade un producto al carrito
    - category-page-view: Cuando un usuario ve p√°ginas especiales, como ofertas o promociones
    - detail-page-view: Cuando un usuario ve la p√°gina de detalle de un producto
    - home-page-view: Cuando un usuario visita la p√°gina de inicio
    - purchase-complete: Cuando un usuario completa una compra
    - search: Cuando un usuario realiza una b√∫squeda
    
    El sistema tambi√©n acepta nombres alternativos simplificados:
    - 'view' o 'detail-page' ‚Üí detail-page-view
    - 'add' o 'cart' ‚Üí add-to-cart
    - 'buy', 'purchase' o 'checkout' ‚Üí purchase-complete
    - 'home' ‚Üí home-page-view
    - 'category' o 'promo' ‚Üí category-page-view
    """
    try:
        # Validar product_id si est√° presente
        if product_id:
            # Verificar si es un ID existente en el cat√°logo
            if tfidf_recommender.loaded and tfidf_recommender.product_data:
                product_exists = any(str(p.get('id', '')) == product_id for p in tfidf_recommender.product_data)
                if not product_exists:
                    # Si el ID no existe, pero es un ID de desarrollo (empieza con 'prod_test_'), permitirlo
                    if not product_id.startswith(('test_', 'prod_test_', '123')):
                        logger.warning(f"ID de producto no encontrado en el cat√°logo: {product_id}")
                        # A√∫n permitimos el evento, pero advertimos
            
        logger.info(f"Registrando evento de usuario: {user_id}, tipo: {event_type}, producto: {product_id or 'N/A'}")
        
        # Registrar el evento
        result = await hybrid_recommender.record_user_event(
            user_id=user_id,
            event_type=event_type,
            product_id=product_id,
            purchase_amount=purchase_amount
        )
        
        # A√±adir informaci√≥n adicional a la respuesta
        if result.get("status") == "success":
            result["detail"] = {
                "user_id": user_id,
                "event_type": result.get("event_type", event_type),
                "product_id": product_id,
                "timestamp": datetime.utcnow().isoformat(),
                "note": "El evento fue registrado correctamente y ayudar√° a mejorar las recomendaciones futuras."
            }
            
            # Registrar interacci√≥n en m√©tricas si est√°n habilitadas
            if settings.metrics_enabled and 'recommendation_metrics' in globals():
                from src.api.core.metrics import recommendation_metrics
                recommendation_metrics.record_user_interaction(
                    user_id=user_id,
                    product_id=product_id,
                    event_type=event_type,
                    recommendation_id=None  # No podemos saber si vino de una recomendaci√≥n sin contexto adicional
                )
        
        return result
    except Exception as e:
        logger.error(f"Error registrando evento de usuario: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Error al registrar el evento: {str(e)}. Aseg√∫rate de usar un tipo de evento v√°lido (detail-page-view, add-to-cart, purchase-complete, category-page-view, home-page-view, search)."
        )

@app.get("/v1/customers/")
async def get_customers(
    current_user: str = Depends(get_current_user)
):
    """
    Obtiene la lista de clientes de Shopify.
    Requiere autenticaci√≥n mediante API key.
    """
    try:
        client = get_shopify_client()
        if not client:
            raise HTTPException(status_code=500, detail="Shopify client not initialized")
            
        customers = client.get_customers()
        
        if not customers:
            logger.warning("No customers found")
            return {
                "total": 0,
                "customers": []
            }
            
        return {
            "total": len(customers),
            "customers": customers
        }
    except Exception as e:
        logger.error(f"Error fetching customers: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    
@app.get("/v1/products/")
async def get_products(
    page: int = Query(1, gt=0, description="N√∫mero de p√°gina"),
    page_size: int = Query(50, gt=0, le=100, description="Resultados por p√°gina")
):
    """
    Obtiene la lista de productos con paginaci√≥n.
    """
    # Log del valor recibido para debugging
    logger.info(f"get_products: Par√°metros recibidos - page={page}, page_size={page_size}")

    # Verificar estado de carga
    is_healthy, reason = startup_manager.is_healthy()
    if not is_healthy:
        raise HTTPException(status_code=503, detail=f"Servicio no disponible: {reason}")
    
    try:
        # Intentar obtener productos de Shopify primero
        client = get_shopify_client()
        if client:
            all_products = client.get_products()
            logger.info(f"Obtenidos {len(all_products)} productos desde Shopify")
        elif tfidf_recommender.loaded and tfidf_recommender.product_data:
            all_products = tfidf_recommender.product_data
            logger.info(f"Obtenidos {len(all_products)} productos desde el recomendador")
        else:
            # Si no hay productos disponibles, devolver respuesta vac√≠a
            return {
                "products": [],
                "total": 0,
                "page": page,
                "page_size": page_size,
                "total_pages": 0,
                "loading_complete": False
            }
        
         # Validar expl√≠citamente page_size para asegurar que se respeta el valor
        actual_page_size = min(page_size, 100)  # Asegurar que no exceda 100
        logger.info(f"Usando page_size={actual_page_size}")
        
        # Calcular √≠ndices de paginaci√≥n
        start_idx = (page - 1) * actual_page_size
        end_idx = start_idx + actual_page_size
        
        # Calcular total de p√°ginas
        total_products = len(all_products)
        total_pages = math.ceil(total_products / actual_page_size)

        # Verificar que los √≠ndices est√°n dentro de l√≠mites
        if start_idx >= total_products:
            # Si p√°gina fuera de rango, devolver √∫ltima p√°gina
            page = total_pages
            start_idx = (page - 1) * actual_page_size
            end_idx = total_products
        
        # Obtener productos paginados
        paginated_products = all_products[start_idx:end_idx]
        logger.info(f"Devolviendo {len(paginated_products)} productos (page={page}, page_size={actual_page_size})")
        
        # Construir y devolver respuesta
        return {
            "products": paginated_products,
            "total": total_products,
            "page": page,
            "page_size": actual_page_size,
            "total_pages": total_pages,
            "loading_complete": True
        }
    except Exception as e:
        logger.error(f"Error obteniendo productos: {e}")
        logger.error("Stack trace:", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error obteniendo productos: {str(e)}")

@app.get("/v1/products/category/{category}")
async def get_products_by_category(
    category: str,
    current_user: str = Depends(get_current_user)
):
    """
    Obtiene productos filtrados por categor√≠a.
    Requiere autenticaci√≥n mediante API key.
    """
    try:
        client = get_shopify_client()
        all_products = []
        
        if client:
            logger.info(f"Obteniendo productos de Shopify para categor√≠a: {category}")
            all_products = client.get_products()
        elif tfidf_recommender.loaded and tfidf_recommender.product_data:
            logger.info(f"Obteniendo productos del recomendador para categor√≠a: {category}")
            all_products = tfidf_recommender.product_data
        else:
            raise HTTPException(
                status_code=503,
                detail="No hay productos disponibles. El servicio est√° cargando."
            )
            
        logger.info(f"Filtrando {len(all_products)} productos por categor√≠a: {category}")
        
        # Filtrar por categor√≠a (product_type en Shopify)
        category_products = [
            p for p in all_products 
            if p.get("product_type", "").lower() == category.lower()
        ]
        
        logger.info(f"Encontrados {len(category_products)} productos en categor√≠a {category}")
        
        if not category_products:
            raise HTTPException(
                status_code=404,
                detail=f"No products found in category: {category}"
            )
        return category_products
    except HTTPException:
        # Re-lanzar excepciones HTTP que ya hemos creado
        raise
    except Exception as e:
        logger.error(f"Error en b√∫squeda por categor√≠a: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/v1/products/search/", response_model=Dict)
async def search_products(
    q: str = Query(..., min_length=1, description="Texto de b√∫squeda"),
    current_user: str = Depends(get_current_user)
):
    """
    Busca productos por texto utilizando similitud TF-IDF.
    Requiere autenticaci√≥n mediante API key.
    """
    # Verificar estado de carga
    is_healthy, reason = startup_manager.is_healthy()
    if not is_healthy:
        raise HTTPException(status_code=503, detail=f"Servicio no disponible: {reason}")
    
    if not tfidf_recommender.loaded:
        return {
            "products": [],
            "total": 0,
            "query": q,
            "loading_complete": False,
            "message": "El buscador est√° cargando. Intente m√°s tarde."
        }
    
    # Realizar b√∫squeda
    start_processing = time.time()
    try:
        results = await tfidf_recommender.search_products(q, 10)
        processing_time_ms = (time.time() - start_processing) * 1000
        
        return {
            "products": results,
            "total": len(results),
            "query": q,
            "loading_complete": True,
            "took_ms": processing_time_ms
        }
    except Exception as e:
        logger.error(f"Error en b√∫squeda de productos: {e}")
        raise HTTPException(status_code=500, detail=f"Error en b√∫squeda: {str(e)}")

# ==========================================
# FASE 2: ENDPOINTS MCP PERSONALIZATION
# ==========================================

@app.post("/v1/mcp/personalized-conversation")
async def personalized_conversation(
    user_id: str,
    message: str,
    market_id: str = "US",
    session_id: Optional[str] = None,
    strategy: str = "hybrid",
    current_user: str = Depends(get_current_user)
):
    """
    Endpoint para conversaciones altamente personalizadas con MCP Personalization Engine.
    
    Args:
        user_id: ID del usuario
        message: Mensaje del usuario
        market_id: Mercado objetivo (US, ES, MX)
        session_id: ID de sesi√≥n (opcional, se genera autom√°ticamente si no se proporciona)
        strategy: Estrategia de personalizaci√≥n (behavioral, cultural, contextual, predictive, hybrid)
        
    Returns:
        Respuesta personalizada con recomendaciones adaptadas al mercado y usuario
    """
    start_processing = time.time()
    
    # Verificar estado de carga
    is_healthy, reason = startup_manager.is_healthy()
    if not is_healthy:
        raise HTTPException(status_code=503, detail=f"Servicio no disponible: {reason}")
    
    # Verificar si el personalization engine est√° disponible
    if not personalization_engine:
        # Fallback a recomendaciones b√°sicas
        try:
            basic_recommendations = await hybrid_recommender.get_recommendations(
                user_id=user_id,
                n_recommendations=5
            )
            
            processing_time = (time.time() - start_processing) * 1000
            
            return {
                "session_id": session_id or f"basic_session_{user_id}_{time.time_ns()}",
                "market_id": market_id,
                "personalized_response": "Te ayudo a encontrar lo que buscas. ¬øQu√© tipo de producto te interesa?",
                "recommendations": basic_recommendations[:5],
                "personalization_metadata": {
                    "strategy_used": "fallback",
                    "personalization_score": 0.3,
                    "engine_available": False,
                    "processing_time_ms": processing_time
                },
                "status": "success_fallback",
                "message": "Personalization engine no disponible - usando recomendaciones b√°sicas"
            }
            
        except Exception as e:
            logger.error(f"Error en fallback de personalizaci√≥n: {e}")
            raise HTTPException(status_code=500, detail="Error en servicio de recomendaciones")
    
    try:
        # Obtener/crear contexto conversacional
        if session_id:
            mcp_context = await mcp_state_manager.load_conversation_state(session_id)
        else:
            session_id = f"session_{user_id}_{int(time.time())}"
            mcp_context = None
        
        if not mcp_context:
            mcp_context = await mcp_state_manager.create_conversation_context(
                session_id=session_id,
                user_id=user_id,
                initial_query=message,
                market_context={"market_id": market_id},
                user_agent="api_client"
            )
        
        # Agregar nuevo turno a la conversaci√≥n
        intent_analysis = {
            "intent": "recommend",
            "confidence": 0.8,
            "entities": [],
            "market_context": {"market_id": market_id}
        }
        
        mcp_context = await mcp_state_manager.add_conversation_turn(
            context=mcp_context,
            user_query=message,
            intent_analysis=intent_analysis,
            ai_response="",  # Se llenar√° despu√©s
            recommendations=[],
            processing_time_ms=0
        )
        
        # Obtener recomendaciones base
        base_recommendations = await hybrid_recommender.get_recommendations(
            user_id=user_id,
            n_recommendations=8
        )
        
        # Mapear estrategia string a enum
        strategy_mapping = {
            "behavioral": PersonalizationStrategy.BEHAVIORAL,
            "cultural": PersonalizationStrategy.CULTURAL,
            "contextual": PersonalizationStrategy.CONTEXTUAL,
            "predictive": PersonalizationStrategy.PREDICTIVE,
            "hybrid": PersonalizationStrategy.HYBRID
        }
        
        selected_strategy = strategy_mapping.get(strategy.lower(), PersonalizationStrategy.HYBRID)
        
        # Aplicar personalizaci√≥n avanzada
        personalized_result = await personalization_engine.generate_personalized_response(
            mcp_context=mcp_context,
            recommendations=base_recommendations,
            strategy=selected_strategy
        )
        
        # Actualizar contexto con respuesta generada
        ai_response = personalized_result["personalized_response"]["response"]
        
        # Guardar estado actualizado
        await mcp_state_manager.save_conversation_state(mcp_context)
        
        processing_time = (time.time() - start_processing) * 1000
        
        return {
            "session_id": session_id,
            "market_id": market_id,
            "personalized_response": ai_response,
            "recommendations": personalized_result["personalized_recommendations"][:5],
            "personalization_metadata": {
                **personalized_result["personalization_metadata"],
                "processing_time_ms": processing_time,
                "conversation_turn": len(mcp_context.turns),
                "engine_available": True
            },
            "conversation_enhancement": personalized_result["conversation_enhancement"],
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"Error en conversaci√≥n personalizada: {e}")
        logger.error("Stack trace:", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error en personalizaci√≥n: {str(e)}")

@app.get("/v1/mcp/user-analytics/{user_id}")
async def get_user_analytics(
    user_id: str,
    market_id: str = "US",
    analysis_depth: str = "standard",
    current_user: str = Depends(get_current_user)
):
    """
    Obtiene an√°lisis comprehensivo del usuario para insights de personalizaci√≥n.
    
    Args:
        user_id: ID del usuario
        market_id: Mercado a analizar
        analysis_depth: Profundidad del an√°lisis (basic, standard, deep)
        
    Returns:
        Reporte completo con insights y recomendaciones de optimizaci√≥n
    """
    start_processing = time.time()
    
    # Verificar si el personalization engine est√° disponible
    if not personalization_engine:
        raise HTTPException(
            status_code=503, 
            detail="MCP Personalization Engine no disponible"
        )
    
    try:
        # Crear analizador de insights
        insights_analyzer = PersonalizationInsightsAnalyzer(redis_client)
        
        # Generar reporte comprehensivo
        user_report = await insights_analyzer.generate_comprehensive_user_report(
            user_id=user_id,
            market_id=market_id,
            analysis_depth=analysis_depth
        )
        
        processing_time = (time.time() - start_processing) * 1000
        
        return {
            "user_report": user_report,
            "metadata": {
                "processing_time_ms": processing_time,
                "analysis_depth": analysis_depth,
                "market_id": market_id,
                "generated_at": time.time()
            },
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"Error generando analytics de usuario: {e}")
        raise HTTPException(status_code=500, detail=f"Error en analytics: {str(e)}")

@app.get("/v1/mcp/health")
async def mcp_health_check():
    """
    Health check espec√≠fico para componentes MCP y Personalization Engine.
    """
    try:
        health_status = {
            "status": "operational",
            "components": {
                "personalization_engine": {
                    "available": personalization_engine is not None,
                    "status": "operational" if personalization_engine else "unavailable"
                },
                "conversation_manager": {
                    "available": optimized_conversation_manager is not None,
                    "status": "operational" if optimized_conversation_manager else "unavailable"
                },
                "state_manager": {
                    "available": mcp_state_manager is not None,
                    "status": "operational" if mcp_state_manager else "unavailable"
                },
                "redis_connection": {
                    "available": redis_client is not None,
                    "connected": redis_client.connected if redis_client else False
                }
            },
            "capabilities": {
                "personalized_conversations": personalization_engine is not None,
                "user_analytics": personalization_engine is not None,
                "market_optimization": personalization_engine is not None,
                "ml_predictions": (
                    personalization_engine.enable_ml_predictions 
                    if personalization_engine else False
                )
            },
            "timestamp": time.time()
        }
        
        # Obtener m√©tricas del personalization engine si est√° disponible
        if personalization_engine:
            try:
                metrics = personalization_engine.get_personalization_metrics()
                health_status["metrics"] = metrics
            except Exception as e:
                health_status["metrics_error"] = str(e)
        
        # Determinar estado general
        critical_components = [
            health_status["components"]["personalization_engine"]["available"],
            health_status["components"]["conversation_manager"]["available"]
        ]
        
        if all(critical_components):
            health_status["status"] = "operational"
        elif any(critical_components):
            health_status["status"] = "degraded"
        else:
            health_status["status"] = "unavailable"
        
        return health_status
        
    except Exception as e:
        logger.error(f"Error en MCP health check: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": time.time()
        }

@app.get("/v1/metrics")
async def get_comprehensive_metrics(current_user: str = Depends(get_current_user)):
    """
    Endpoint de m√©tricas comprehensivo para validaci√≥n de Fase 2
    
    Incluye m√©tricas de:
    - Sistema general
    - Personalizaci√≥n 
    - Performance
    - MCP integration
    """
    try:
        metrics_response = {
            "timestamp": time.time(),
            "system_metrics": {
                "uptime_seconds": time.time() - start_time,
                "total_requests": getattr(app.state, 'total_requests', 0),
                "active_sessions": getattr(app.state, 'active_sessions', 0),
                "memory_usage_mb": 0,  # Placeholder
                "cpu_usage_percent": 0  # Placeholder
            },
            "realtime_metrics": {
                "average_response_time_ms": getattr(app.state, 'avg_response_time', 0),
                "p95_response_time_ms": getattr(app.state, 'p95_response_time', 0),
                "p99_response_time_ms": getattr(app.state, 'p99_response_time', 0),
                "cache_hit_ratio": 0.85,  # Placeholder
                "fallback_rate": 0.05  # Placeholder
            },
            "business_metrics": {
                "recommendations_by_source": {
                    "content_based": 45.2,
                    "collaborative": 54.8
                },
                "user_interactions": {
                    "conversations": getattr(app.state, 'conversations_count', 0),
                    "recommendations_generated": getattr(app.state, 'recommendations_count', 0),
                    "personalization_applied": getattr(app.state, 'personalization_count', 0)
                }
            }
        }
        
        # ‚úÖ A√ëADIR: M√©tricas de personalizaci√≥n si est√° disponible
        try:
            if hasattr(app.state, 'personalization_engine') or (
                hasattr(globals().get('personalization_engine', {}), 'get_personalization_metrics')
            ):
                personalization_engine = getattr(app.state, 'personalization_engine', None)
                if not personalization_engine:
                    from src.api import main_unified_redis
                    personalization_engine = getattr(main_unified_redis, 'personalization_engine', None)
                
                if personalization_engine:
                    p_metrics = personalization_engine.get_personalization_metrics()
                    metrics_response["personalization_metrics"] = p_metrics
                else:
                    metrics_response["personalization_metrics"] = {
                        "status": "not_available",
                        "personalizations_generated": 0,
                        "strategies_available": ["hybrid", "behavioral", "cultural", "contextual"],
                        "ml_predictions_enabled": False
                    }
        except Exception as e:
            logger.warning(f"Error getting personalization metrics: {e}")
            metrics_response["personalization_metrics"] = {"error": str(e)}
        
        # ‚úÖ A√ëADIR: M√©tricas de cache si est√° disponible
        try:
            if redis_client:
                cache_stats = {
                    "redis_connected": redis_client.connected if hasattr(redis_client, 'connected') else True,
                    "cache_enabled": True,
                    "hit_ratio": 0.87,  # Placeholder - se puede obtener de ProductCache
                    "total_keys": 0,  # Placeholder
                    "memory_usage": "unknown"
                }
                metrics_response["cache_metrics"] = cache_stats
            else:
                metrics_response["cache_metrics"] = {
                    "redis_connected": False,
                    "cache_enabled": False
                }
        except Exception as e:
            metrics_response["cache_metrics"] = {"error": str(e)}
        
        # ‚úÖ A√ëADIR: M√©tricas de MCP si est√° disponible
        try:
            mcp_metrics = {
                "mcp_available": mcp_recommender is not None,
                "bridge_status": "unknown",
                "mcp_requests": getattr(app.state, 'mcp_requests', 0),
                "mcp_success_rate": getattr(app.state, 'mcp_success_rate', 0.95)
            }
            
            # Intentar obtener m√©tricas del MCP recommender
            if mcp_recommender and hasattr(mcp_recommender, 'get_metrics'):
                try:
                    mcp_detailed = mcp_recommender.get_metrics()
                    mcp_metrics.update(mcp_detailed)
                except:
                    pass
            
            metrics_response["mcp_metrics"] = mcp_metrics
            
        except Exception as e:
            metrics_response["mcp_metrics"] = {"error": str(e)}
        
        return metrics_response
        
    except Exception as e:
        logger.error(f"Error generating metrics: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving metrics: {str(e)}"
        )

# ==========================================
# FASE 3: ENDPOINTS DE HEALTH, MONITORING Y SECURITY
# ==========================================

@app.get("/health/claude", 
         summary="Claude Health Check Extendido",
         description="Health check comprehensivo espec√≠fico para la integraci√≥n Claude",
         tags=["Claude"])
async def claude_health_endpoint():
    """
    Endpoint de health check extendido espec√≠fico para Claude.
    """
    if not CLAUDE_HEALTH_AVAILABLE:
        return Response(
            content=json.dumps({
                "status": "unavailable", 
                "message": "Claude health module not available",
                "timestamp": time.time()
            }),
            status_code=503,
            media_type="application/json"
        )
    
    try:
        health_result = await get_claude_health()
        
        # Determinar status code basado en el resultado
        overall_status = health_result.get("overall_status", "unknown")
        
        if overall_status == "healthy":
            status_code = 200
        elif overall_status == "degraded":
            status_code = 200  # Still operational but with warnings
        else:
            status_code = 503  # Service unavailable
        
        return Response(
            content=json.dumps(health_result, indent=2),
            status_code=status_code,
            media_type="application/json"
        )
        
    except Exception as e:
        logger.error(f"Error in Claude health check: {e}")
        return Response(
            content=json.dumps({
                "overall_status": "unhealthy",
                "error": str(e),
                "timestamp": time.time()
            }, indent=2),
            status_code=503,
            media_type="application/json"
        )

@app.get("/v1/metrics/claude",
         summary="M√©tricas Avanzadas de Claude",
         description="M√©tricas detalladas en tiempo real de la integraci√≥n Claude",
         tags=["Claude"])
async def claude_metrics_endpoint(
    api_key: str = Depends(get_api_key),
    historical_hours: int = Query(default=1, description="Horas de datos hist√≥ricos", ge=1, le=168)
):
    """
    Endpoint de m√©tricas avanzadas espec√≠ficas de Claude.
    """
    if not CLAUDE_MONITORING_AVAILABLE:
        return {
            "status": "unavailable", 
            "message": "Claude monitoring module not available",
            "timestamp": time.time()
        }
    
    try:
        # M√©tricas en tiempo real
        realtime_metrics = await get_claude_metrics()
        
        # M√©tricas hist√≥ricas si se solicitan
        historical_metrics = None
        if historical_hours > 1:
            historical_metrics = await get_claude_historical_metrics(historical_hours)
        
        # Alertas activas
        alerts = await get_claude_alerts()
        
        response_data = {
            "timestamp": time.time(),
            "realtime_metrics": realtime_metrics,
            "historical_metrics": historical_metrics,
            "alerts": alerts,
            "metadata": {
                "api_version": "1.0",
                "claude_integration_version": "2.0",
                "metrics_collection_enabled": True
            }
        }
        
        return response_data
        
    except Exception as e:
        logger.error(f"Error retrieving Claude metrics: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving Claude metrics: {str(e)}"
        )

@app.get("/v1/security/claude/audit",
         summary="Auditor√≠a de Seguridad Claude",
         description="Ejecuta auditor√≠a de seguridad comprehensiva para la integraci√≥n Claude",
         tags=["Claude"])
async def claude_security_audit_endpoint(
    api_key: str = Depends(get_api_key),
    force_refresh: bool = Query(default=False, description="Forzar nueva auditor√≠a")
):
    """
    Endpoint de auditor√≠a de seguridad para Claude.
    """
    if not CLAUDE_SECURITY_AVAILABLE:
        return {
            "status": "unavailable", 
            "message": "Claude security audit module not available",
            "timestamp": time.time()
        }
    
    try:
        # Verificar cache de auditor√≠a (auditor√≠as son costosas)
        cache_key = "claude_security_audit"
        cached_result = None
        
        if not force_refresh and hasattr(app.state, 'audit_cache'):
            cached_result = app.state.audit_cache.get(cache_key)
            if cached_result and time.time() - cached_result.get('timestamp', 0) < 3600:  # 1 hora cache
                cached_result['from_cache'] = True
                return cached_result
        
        # Ejecutar nueva auditor√≠a
        logger.info("üîí Executing Claude security audit...")
        audit_result = await run_claude_security_audit()
        
        # Guardar en cache
        if not hasattr(app.state, 'audit_cache'):
            app.state.audit_cache = {}
        app.state.audit_cache[cache_key] = audit_result
        
        audit_result['from_cache'] = False
        return audit_result
        
    except Exception as e:
        logger.error(f"Error in Claude security audit: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error executing security audit: {str(e)}"
        )

@app.get("/v1/alerts/claude",
         summary="Alertas de Claude",
         description="Obtiene alertas activas y resueltas de la integraci√≥n Claude",
         tags=["Claude"])
async def claude_alerts_endpoint(
    api_key: str = Depends(get_api_key),
    include_resolved: bool = Query(default=False, description="Incluir alertas resueltas")
):
    """
    Endpoint de alertas espec√≠ficas de Claude.
    """
    if not CLAUDE_MONITORING_AVAILABLE:
        return {
            "status": "unavailable", 
            "message": "Claude monitoring module not available",
            "timestamp": time.time()
        }
    
    try:
        alerts_data = await get_claude_alerts()
        
        if not include_resolved:
            # Filtrar solo alertas activas
            alerts_data['resolved_alerts_last_24h'] = []
        
        return alerts_data
        
    except Exception as e:
        logger.error(f"Error retrieving unified Claude alerts: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving alerts: {str(e)}"
        )

@app.get("/v1/loadtest/claude/status",
         summary="Estado de Load Testing",
         description="Obtiene el estado actual para load testing de Claude - UNIFICADO",
         tags=["Claude"])
async def claude_loadtest_status(api_key: str = Depends(get_api_key)):
    """
    Endpoint unificado para verificar que el sistema est√° listo para load testing.
    Usa ObservabilityManager para determinar readiness de manera consistente.
    """
    try:
        # Usar ObservabilityManager si est√° disponible
        if OBSERVABILITY_MANAGER_AVAILABLE:
            observability = get_observability_manager()
            return await observability.get_loadtest_response()
        
        # Fallback a implementaci√≥n original
        elif CLAUDE_HEALTH_AVAILABLE and CLAUDE_MONITORING_AVAILABLE:
            health = await get_claude_health()
            metrics = await get_claude_metrics()
            
            # Determinar readiness para load testing (mantener l√≥gica original)
            is_ready = (
                health.get("overall_status") == "healthy" and
                metrics.get("performance_metrics", {}).get("sla_compliance", False)
            )
            
            return {
                "loadtest_ready": is_ready,
                "current_status": health.get("overall_status"),
                "sla_compliance": metrics.get("performance_metrics", {}).get("sla_compliance"),
                "current_response_time_p95": metrics.get("performance_metrics", {}).get("p95_response_time_ms"),
                "active_alerts": len(metrics.get("alerts", {}).get("recent_alerts", [])),
                "recommendations": [
                    "System ready for load testing" if is_ready else "Resolve health issues before load testing",
                    "Monitor /v1/metrics/claude during testing",
                    "Use /health/claude for real-time status"
                ],
                "test_endpoints": [
                    "/v1/mcp/conversation",
                    "/v1/recommendations/user/{user_id}",
                    "/v1/products/search/"
                ],
                "unified_monitoring": False
            }
        else:
            return {
                "loadtest_ready": False,
                "current_status": "modules_unavailable",
                "message": "Claude health and monitoring modules required for load testing status",
                "test_endpoints": [
                    "/v1/mcp/conversation",
                    "/v1/recommendations/user/{user_id}",
                    "/v1/products/search/"
                ],
                "unified_monitoring": False
            }
        
    except Exception as e:
        logger.error(f"Error checking unified loadtest status: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error checking loadtest readiness: {str(e)}"
        )

# === MIDDLEWARE UNIFICADO PARA OBSERVABILITY ===
@app.middleware("http")
async def unified_observability_middleware(request, call_next):
    """
    Middleware unificado que alimenta al ObservabilityManager.
    Reemplaza el claude_metrics_middleware anterior para evitar duplicaci√≥n.
    """
    start_time = time.time()
    
    # Detectar si es una request relacionada con Claude
    is_claude_request = (
        "/mcp/" in str(request.url) or 
        "/conversation" in str(request.url) or
        "claude" in str(request.url).lower()
    )
    
    response = await call_next(request)
    
    # Si es una request de Claude, alimentar al observability manager
    if is_claude_request:
        response_time_ms = (time.time() - start_time) * 1000
        success = 200 <= response.status_code < 400
        
        # Extraer informaci√≥n adicional si est√° disponible
        user_id = request.headers.get("X-User-ID")
        market_id = request.headers.get("X-Market-ID")
        
        try:
            # Usar ObservabilityManager si est√° disponible
            if OBSERVABILITY_MANAGER_AVAILABLE:
                observability = get_observability_manager()
                
                # ‚úÖ CORRECCI√ìN: NO usar metrics_collector, alimentar directamente
                # Actualizar m√©tricas mock internas para mantener funcionalidad
                if hasattr(observability, '_mock_metrics'):
                    observability._mock_metrics["total_requests"] = observability._mock_metrics.get("total_requests", 0) + 1
                    if success:
                        observability._mock_metrics["successful_requests"] = observability._mock_metrics.get("successful_requests", 0) + 1
                    else:
                        observability._mock_metrics["failed_requests"] = observability._mock_metrics.get("failed_requests", 0) + 1
                    
                    # Actualizar promedio m√≥vil de tiempo de respuesta
                    current_avg = observability._mock_metrics.get("average_response_time_ms", 500.0)
                    observability._mock_metrics["average_response_time_ms"] = (current_avg * 0.9) + (response_time_ms * 0.1)
                    
                    # Actualizar error rate
                    total = observability._mock_metrics["total_requests"]
                    failed = observability._mock_metrics["failed_requests"]
                    observability._mock_metrics["error_rate"] = failed / total if total > 0 else 0.0
                    
                    logger.debug(f"üìä Unified metrics updated: total={total}, error_rate={failed/total:.3f}, avg_time={observability._mock_metrics['average_response_time_ms']:.1f}ms")
                
            elif CLAUDE_MONITORING_AVAILABLE:
                # Fallback a implementaci√≥n original
                await record_claude_request(
                    success=success,
                    response_time_ms=response_time_ms,
                    user_id=user_id,
                    market_id=market_id,
                    error_type="http_error" if not success else None
                )
        except Exception as e:
            logger.warning(f"Failed to record unified metrics: {e}")
    
    return response

# ‚úÖ CORRECCI√ìN ADICIONAL: Middleware para tracking de m√©tricas
@app.middleware("http")
async def metrics_tracking_middleware(request, call_next):
    """Middleware para trackear m√©tricas b√°sicas"""
    start_time = time.time()
    
    # Incrementar contador de requests
    if not hasattr(app.state, 'total_requests'):
        app.state.total_requests = 0
    app.state.total_requests += 1
    
    response = await call_next(request)
    
    # Calcular tiempo de respuesta
    response_time = (time.time() - start_time) * 1000
    
    # Actualizar m√©tricas de tiempo de respuesta (promedio m√≥vil simple)
    if not hasattr(app.state, 'avg_response_time'):
        app.state.avg_response_time = response_time
    else:
        app.state.avg_response_time = (app.state.avg_response_time * 0.9) + (response_time * 0.1)
    
    # Trackear m√©tricas espec√≠ficas por endpoint
    if "/mcp/" in str(request.url):
        if not hasattr(app.state, 'mcp_requests'):
            app.state.mcp_requests = 0
        app.state.mcp_requests += 1
    
    return response

# Configuraci√≥n para ejecutar con uvicorn
if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("main_unified_redis:app", host="0.0.0.0", port=port, reload=True)
